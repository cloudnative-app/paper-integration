# 4. 표준화의 위력, 그리고 MCP가 할 수 없는 것들

지난 3편에서는 MCP 시스템이 지휘자(호스트 앱), 연주자(MCP 서버), 소통 담당자(MCP 클라이언트), 악곡 해석가(LLM)의 협업으로 이루어지며, '만능 번역기'(Transport)를 통해 놀라운 유연성을 갖는다는 것을 배웠습니다.

**[3편 다시보기: AI 시스템의 협업 방식: 서버, 클라이언트, 호스트 앱, 그리고 '만능 번역기' Transport](part3.md)**

이번 4편에서는 MCP가 왜 그토록 '표준화'를 강조하는지 그 이유를 다시 한번 되짚어보고, 비슷한 목표를 가진 'Function Calling'과는 어떤 결정적인 차이가 있는지, 그리고 MCP가 제공하는 가치에도 불구하고 왜 "MCP만 있으면 다 된다"고 말할 수 없는지, 그 명확한 한계점을 알아보겠습니다.

### 1. 비교 대상: Function Calling (Tool Calling) 살펴보기

MCP를 더 잘 이해하려면, 비슷한 역할을 하는 Function Calling(또는 Tool Calling)을 알면 도움이 됩니다. 이는 LLM이 사용자의 요청을 분석하다가 "아, 이 부분은 내가 직접 답하는 것보다 외부 도구(함수)를 쓰는 게 좋겠어!"라고 판단했을 때, 어떤 함수를 어떤 정보(인자)와 함께 호출해야 하는지를 알려주는 기능입니다. LLM이 '도구 사용 제안서'를 보내면, 호스트 앱이 그 제안을 받아 실제 도구를 실행하고 결과를 다시 LLM에게 알려주는 방식이죠.

### 2. MCP vs Function Calling: 결정적 차이점은?

둘 다 LLM이 외부 세계와 소통하게 한다는 점은 같지만, 접근 방식에 차이가 있습니다.

* **'표준'의 범위:**
    * **Function Calling:** 주로 LLM 제공사(OpenAI, Google 등)별로 자체 API 규격 안에서 구현됩니다. 마치 특정 브랜드의 가전제품에만 맞는 전용 리모컨과 같습니다. 브랜드마다 리모컨 모양이나 버튼 기능이 조금씩 다르죠.
    * **MCP:** LLM 제공사나 특정 플랫폼에 **종속되지 않는, 개방된 '공용 리모컨' 규격**을 만들려고 합니다. JSON-RPC라는 표준 신호 방식을 사용하고, `tools/list`, `tools/call` 같은 표준 버튼(명령)을 정의합니다. 이 규격만 맞으면 어떤 브랜드의 TV(호스트 앱/LLM)라도 이 공용 리모컨(MCP 클라이언트)으로 표준 규격을 지원하는 셋톱박스(MCP 서버)를 제어할 수 있게 하는 것이 목표입니다.
* **'연결'의 유연성:**
    * **Function Calling:** 일반적으로 LLM의 제안을 받은 호스트 앱 코드가 직접 호출할 수 있는 형태로 도구가 준비되어 있어야 합니다.
    * **MCP:** 3편의 '만능 번역기' **`Transport`** 덕분에, 원래 MCP 규격을 따르지 않는 기존의 다양한 서비스나 기능(오래된 가전제품?)도 '번역 어댑터'를 통해 MCP 시스템에 쉽게 연결할 수 있습니다. 훨씬 폭넓은 연결성을 제공하죠.

### 3. MCP 핵심 가치: '표준화'는 왜 강력한가?

MCP가 '공용 리모컨'이나 '표준 컨테이너'처럼 표준화를 추구하는 이유는 그것이 엄청난 힘을 가지기 때문입니다.

* **호환성:** 표준 규격만 맞으면 서로 다른 회사에서 만든 제품이라도 문제없이 함께 작동합니다.
* **단순함:** 여러 개의 복잡한 사용법 대신 하나의 표준만 배우면 되니 훨씬 쉽고 빠릅니다.
* **개방성:** 누구나 표준에 맞춰 제품(도구)을 만들고 참여할 수 있어 혁신적인 아이디어가 샘솟는 생태계가 만들어집니다.
* **결합성:** 표준화된 부품들을 레고처럼 쉽게 조립하여 새로운 가치를 만들 수 있습니다.

MCP는 LLM과 도구가 만나는 복잡한 세계에 바로 이 '표준화'의 마법을 불어넣으려 합니다.

### 4. 그러나 MCP는 '은 탄환'이 아니다: 명확한 한계점

MCP가 훌륭한 표준화 시도인 것은 분명하지만, 이것만으로 모든 AI 문제가 해결되는 것은 절대 아닙니다. **MCP는 연결 통로일 뿐, 지능 그 자체가 아닙니다.**

* **MCP는 '연결 규격' 그 이상도 이하도 아님:** MCP는 LLM을 포함하고 있지 않으며, 스스로 판단하거나 학습하지 않습니다. 단순히 정해진 약속(프로토콜)에 따라 메시지를 주고받는 역할만 합니다.
* **판단과 실행의 주체는 '호스트 앱':**
    * "지금 도구를 써야 할까?"
    * "수많은 도구 중에 어떤 걸 써야 할까?" (`tools/list` 결과를 보고 판단)
    * "LLM이 제안한 도구 호출이 적절한가?"
    * "도구 실행 결과(예: 웹 검색 결과)를 어떻게 해석해서 LLM에게 다시 질문해야 할까?"
    * "전체 대화는 어떻게 매끄럽게 이어가야 할까?"
    이 모든 **지능적인 판단, 의사 결정, 작업 흐름(워크플로우) 관리는 전적으로 '호스트 앱'의 책임**입니다. 호스트 앱이 얼마나 똑똑하게 LLM과 MCP 서버(도구) 사이에서 '지휘'하느냐에 따라 전체 AI 시스템의 성능이 결정됩니다.
* **결론: MCP는 '멍텅구리 파이프', 지능은 '호스트 앱'에!** MCP는 데이터와 명령이 오가는 매우 효율적이고 표준화된 '파이프'를 제공하지만, 그 파이프를 통해 무엇을 흘려보낼지, 언제 흘려보낼지, 그리고 흘러온 결과를 어떻게 사용할지는 파이프 양 끝단, 특히 '호스트 앱'과 그 안의 LLM에게 달려있습니다.

### 정리 및 다음 편 예고

이번 편에서는 MCP가 Function Calling과 비교했을 때 '표준화'와 '유연성'에서 어떤 차별점을 가지는지, 그리고 그 핵심 가치가 바로 '표준화'에 있음을 확인했습니다. 동시에, MCP는 통신 규약일 뿐이며 실제 지능적인 작업 수행은 전적으로 '호스트 앱'의 역할이라는 중요한 한계점도 명확히 했습니다.

이제 MCP의 역할과 한계를 명확히 알았으니, 마지막 **5편**에서는 이 표준화된 '파이프'가 미래에 어떤 놀라운 구조물들을 가능하게 할지 상상력을 펼쳐보겠습니다. **워크플로우 자체를 MCP 서비스로 만들거나, 여러 AI 에이전트들이 MCP를 통해 협업하고, MCP 서비스 마켓플레이스**가 생겨나는 등, MCP가 AI 개발 생태계를 어떻게 혁신할 수 있을지에 대한 흥미로운 전망을 그려보며 시리즈를 마무리하겠습니다!

MCP가 깔아놓은 길 위에서 어떤 미래가 펼쳐질까요? 마지막 여정을 함께해주세요! 